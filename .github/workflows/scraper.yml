name: Scraper Workflow

on:
  workflow_dispatch:
    inputs:
      wp_base_url:
        description: 'WordPress Base URL (e.g., https://your-site.com)'
        required: true
      wp_username:
        description: 'WordPress username for REST API authentication'
        required: true
      wp_app_password:
        description: 'WordPress application password for REST API authentication'
        required: true
      scrape_location:
        description: 'Location for job scraping (e.g., Worldwide, New York)'
        required: true
      wp_rest_nonce:
        description: 'WordPress REST API nonce'
        required: true

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 urllib3

      - name: Run scraper
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python scraper.py \
            --wp-base-url "${{ github.event.inputs.wp_base_url }}" \
            --wp-username "${{ github.event.inputs.wp_username }}" \
            --wp-app-password "${{ github.event.inputs.wp_app_password }}" \
            --scrape-location "${{ github.event.inputs.scrape_location }}" \
            --wp-rest-nonce "${{ github.event.inputs.wp_rest_nonce }}" | tee scrape_results.txt

      - name: Upload results as artifact
        uses: actions/upload-artifact@v4
        with:
          name: scraper-results
          path: scrape_results.json
          if-no-files-found: error
          compression-level: 0
          include-hidden-files: false
